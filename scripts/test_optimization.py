import asyncio
import os
import sys
import logging

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã¸ã®ãƒ‘ã‚¹è¨­å®š
# (å®Ÿè¡Œç’°å¢ƒã«åˆã‚ã›ã¦é©å®œèª¿æ•´ã—ã¦ãã ã•ã„)
sys.path.append(os.path.join(os.path.dirname(__file__), ".."))

# å®Ÿéš›ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹æˆã«åˆã‚ã›ã¦importã—ã¦ãã ã•ã„
# ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹å ´åˆã¯ãƒ€ãƒŸãƒ¼ç­‰ã®èª¿æ•´ãŒå¿…è¦ã§ã™
try:
    from app.graph.workflow import route_signal
    from app.graph.nodes import summarizer, silence_handler
    from app.graph.state import get_initial_state
except ImportError:
    # ãƒ­ãƒ¼ã‚«ãƒ«ã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã™ã‚‹ãŸã‚ã«ã€importã§ããªã„å ´åˆã®ãƒ€ãƒŸãƒ¼å®šç¾©ã‚’å…¥ã‚Œã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™
    # ã“ã“ã§ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼æ§˜ã®ç’°å¢ƒãŒæ•´ã£ã¦ã„ã‚‹å‰æã§é€²ã‚ã¾ã™
    pass

# ãƒ­ã‚°è¨­å®š: å†…éƒ¨å‹•ä½œãŒè¦‹ãˆã‚‹ã‚ˆã†ã«èª¿æ•´
logging.basicConfig(level=logging.INFO, format="%(message)s")
logging.getLogger("app.graph.nodes").setLevel(logging.INFO)
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("openai").setLevel(logging.WARNING)


async def main():
    print("\n==================================================")
    print("   Optimization Logic Test")
    print("   Target: Router, Summarizer, SilenceHandler")
    print("==================================================\n")

    state = get_initial_state()
    user_alice = "Alice"
    user_bob = "Bob"

    # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®šï¼ˆå…±é€šç‚¹ï¼šæ˜ ç”»ã€æ—…è¡Œï¼‰
    state["profiles"] = {
        user_alice: {
            "user_id": user_alice,
            "interest_clusters": [{"keywords": ["Movie", "Action", "Travel"]}],
            "sns_data": {"likes": ["Cinema", "Kyoto"]},
        },
        user_bob: {
            "user_id": user_bob,
            "interest_clusters": [{"keywords": ["Movie", "Popcorn", "Hot Spring"]}],
            "sns_data": {"likes": ["Netflix", "Travel"]},
        },
    }

    # --------------------------------------------------
    # Case 1: Summarizer Test (å±¥æ­´åœ§ç¸®)
    # --------------------------------------------------
    print("ğŸ§ª [Test Case 1] Summarizer (Maintenance Path)")
    print("   Condition: History length >= Threshold (8)")

    # â˜…å¤‰æ›´ç‚¹: forãƒ«ãƒ¼ãƒ—ã§ã¯ãªãã€æ–‡è„ˆã®ã‚ã‚‹å…·ä½“çš„ãªä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚’ã‚»ãƒƒãƒˆã—ã¾ã™
    # é–¾å€¤(8)ã‚’è¶…ãˆã‚‹ã‚ˆã†ã«10ä»¶ç”¨æ„
    dummy_history = [
        {
            "speaker": user_alice,
            "text": "ã­ãˆã€æœ€è¿‘ä½•ã‹é¢ç™½ã„æ˜ ç”»è¦³ãŸï¼Ÿ",
            "timestamp": 1000,
        },
        {
            "speaker": user_bob,
            "text": "ã‚ã‚ã€å…ˆé€±å…¬é–‹ã•ã‚ŒãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ˜ ç”»ã€ã™ã”ãè‰¯ã‹ã£ãŸã‚ˆï¼",
            "timestamp": 1001,
        },
        {
            "speaker": user_alice,
            "text": "ã¸ãˆã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å¥½ããªã‚“ã ã€‚ç§ã‚‚ãŸã¾ã«è¦³ã‚‹ã‚ˆã€‚",
            "timestamp": 1002,
        },
        {
            "speaker": user_bob,
            "text": "æ˜ ç”»é¤¨ã§é£Ÿã¹ã‚‹ãƒãƒƒãƒ—ã‚³ãƒ¼ãƒ³ãŒæœ€é«˜ãªã‚“ã ã‚ˆã­ã€‚",
            "timestamp": 1003,
        },
        {
            "speaker": user_alice,
            "text": "ã‚ã‹ã‚‹ï¼æ˜ ç”»é¤¨ã®é›°å›²æ°—ã„ã„ã‚ˆã­ã€‚ãã†ã„ãˆã°æ—…è¡Œã¯ï¼Ÿ",
            "timestamp": 1004,
        },
        {
            "speaker": user_bob,
            "text": "æœ€è¿‘è¡Œã‘ã¦ãªã„ãªã‚ã€‚æ¸©æ³‰ã¨ã‹è¡ŒããŸã„ã€‚",
            "timestamp": 1005,
        },
        {
            "speaker": user_alice,
            "text": "äº¬éƒ½ã®æ¸©æ³‰ã¨ã‹ã©ã†ï¼Ÿã“ã‚Œã‹ã‚‰ã®å­£ç¯€ã„ã„ã‹ã‚‚ã€‚",
            "timestamp": 1006,
        },
        {
            "speaker": user_bob,
            "text": "ã„ã„ã­ãˆã€äº¬éƒ½ã€‚Netflixã§äº¬éƒ½ãŒèˆå°ã®æ˜ ç”»è¦³ã¦è¡ŒããŸããªã£ã¦ãŸã‚“ã ã€‚",
            "timestamp": 1007,
        },
        {
            "speaker": user_alice,
            "text": "ã‚ã€ãã‚Œç§ã‚‚è¦³ãŸã‹ã‚‚ï¼æ™¯è‰²ç¶ºéº—ã ã£ãŸã‚ˆã­ã€‚",
            "timestamp": 1008,
        },
        {
            "speaker": user_bob,
            "text": "ãã†ãã†ã€‚ã‚„ã£ã±ã‚Šå®Ÿéš›ã«ç¾åœ°ã«è¡ŒããŸã„ãªã‚ã€‚",
            "timestamp": 1009,
        },
    ]

    state["history_window"] = dummy_history
    state["summary"] = "ä¼šè©±é–‹å§‹ã€‚"  # åˆæœŸã‚µãƒãƒªãƒ¼
    state["input_type"] = "text"  # é€šå¸¸å…¥åŠ›ãƒ¢ãƒ¼ãƒ‰

    # 1. Router Check
    print("   [Check 1] Router Decision")
    next_node = route_signal(state)
    print(f"   -> Result: {next_node}")

    if next_node == "summarizer":
        print("   âœ… OK: Correctly directed to Summarizer.")
    else:
        print(f"   âŒ Failed: Expected 'summarizer', got '{next_node}'.")

    # 2. Summarizer Execution
    print("\n   [Check 2] Summarizer Execution")
    # ã“ã“ã§SummarizerãŒèµ°ã‚Šã€è¦ç´„ç”Ÿæˆã¨å±¥æ­´ã®åœ§ç¸®ãŒè¡Œã‚ã‚Œã¾ã™
    updates = await summarizer(state)

    new_history = updates.get("history_window", [])
    new_summary = updates.get("summary", "")

    print(f"   Old History Len: {len(dummy_history)}")
    print(f"   New History Len: {len(new_history)} (Expected: 2)")
    print(f"   New Summary    : {new_summary}")

    # åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯
    if len(new_history) == 2 and len(new_summary) > 10:
        print("   âœ… OK: History compressed and summary updated.")
    else:
        print("   âŒ Failed: History not compressed correctly.")

    # --------------------------------------------------
    # Case 2: Silence Handler Test (é«˜é€Ÿãƒ‘ã‚¹)
    # --------------------------------------------------
    print("\n--------------------------------------------------")
    print("ğŸ§ª [Test Case 2] SilenceHandler (Fast Path)")
    print("   Condition: input_type == 'silence'")

    # å…¥åŠ›ã‚’ã€Œæ²ˆé»™ã€ã«è¨­å®š
    state["input_type"] = "silence"

    # 1. Router Check
    print("   [Check 1] Router Decision")
    next_node = route_signal(state)
    print(f"   -> Result: {next_node}")

    if next_node == "silence_handler":
        print("   âœ… OK: Correctly directed to SilenceHandler.")
    else:
        print(f"   âŒ Failed: Expected 'silence_handler', got '{next_node}'.")

    # 2. SilenceHandler Execution
    print("\n   [Check 2] SilenceHandler Execution")

    # ç›´å‰ã®å±¥æ­´ã‚„ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã«åŸºã¥ã„ã¦è©±é¡Œã‚’æä¾›ã™ã‚‹ã‹ãƒ†ã‚¹ãƒˆ
    updates = await silence_handler(state)
    final_sugs = updates.get("final_suggestions", [])

    if final_sugs:
        sug = final_sugs[0]
        print(f"   Generated Text: {sug['text']}")
        print(f"   Speaker       : {sug['speaker']} (Should be Alice or Bob)")
        print(f"   Type          : {sug['type']}")

        # ç°¡æ˜“è©•ä¾¡: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹
        text = sug["text"]
        keywords = [
            "æ˜ ç”»",
            "Movie",
            "æ—…è¡Œ",
            "Travel",
            "æ¸©æ³‰",
            "äº¬éƒ½",
            "ã‚¢ã‚¯ã‚·ãƒ§ãƒ³",
            "Netflix",
        ]
        if any(w in text for w in keywords):
            print("   âœ… OK: Topic generated based on common interests/context.")
        else:
            print("   âš ï¸ Check Content manually (might be generic).")

        # AIã£ã½ã•ã®ãƒã‚§ãƒƒã‚¯
        if "ãŠäºŒäººã¯" in text or "è©±é¡Œã‚’å¤‰ãˆã¾ã—ã‚‡ã†" in text:
            print("   âŒ Failed: Sounding too robotic/AI-like.")
        else:
            print("   âœ… OK: Natural phrasing.")

    else:
        print("   âŒ Failed: No suggestions generated.")

    print("\n==================================================")
    print("   Tests Completed")


if __name__ == "__main__":
    asyncio.run(main())
